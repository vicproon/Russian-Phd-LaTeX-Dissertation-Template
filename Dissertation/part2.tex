\chapter{Подавление артефактов, вызванных наличием сильнопоглощающих включений} \label{chapt2}
\section{Введение}

В данной главе рассматривается задача исправления ошибок реконструкции, возникающих при томографии сложных объектов, содержащих области сильного поглощения рентгеновского излучения.
Наличие подобных артефактов (рис. \ref{im:high_absorb_artifacts}) сильно затрудняет последующий анализ результатов томографии.
Поэтому необходимо использовать алгоритмы, учитывающие специфику исследуемого объекта и позволяющие уменьшить влияние сильнопоглощающих включений на результаты восстановления.
Часто такие артефакты возникают при анализе медицинских изображений, если в костях или мягких тканях объекта присутствуют металлические включения.
Например в стоматологии, металлический штифт, необходимый для установки коронки, может быть причиной возникновения ложных полостей в зубе, что может быть причиной неправильного решения об успешности проведенного лечения.
Поэтому такие артефакты так же называют металлическими, хотя они могут возникать в объектах разного состава при соответствующих интенсивности истоячника и чувствительности детектора.
Термин ``сильнопоглощающие'' применим к более широкому набору условий экспериментов, но часто артефакты все равно называют металлическими.


Обычно для подавления этих артефактов на алгоритмическом уровне используют методы, основанные на предобработке синограммы, модификации алгебраических методов на основе методов максимального правдоподобия или выпуклого программирования.
В данной главе будут исследованы методы подавления металлических артефактов на этапе алгоритма восстановления.
Первый метод, предложенный и реализованный автором, использует математический аппарат квадратичного программирования в рамках специально построенной модели формирования металлических артефактов.
Возникновение артефактов в ней выражается в виде неучтенных при восстановлении линейных ограничений-неравенств, которые в купе с квадратичной функцией потерь исходной оптимизационной задачи алгебраического метода и позволяют использовать аппарат численной условной оптимизации.
Второй метод, реализованный Соколовым В., основываясь на той же модели формирования артефактов, решает задачу восстановления путем добавления аддитивных мягких ограничений за нарушение неравенств модели.
Автором была произведена настройка параметров метода и получение приведенных в главе результатов.
Наконец, производится сравнение результатов восстановления обоих методов на модельном примере.

\begin{figure}
\centering
\begin{tabular}{@{}c@{}c}
  \includegraphics[width=0.3\textwidth]{part2_img/tooth_artifacts_med}
  &
  \includegraphics[width=0.3\textwidth]{../Presentation/images/high_absorb_artifacts}
\\
\end{tabular}
\caption{Примеры артефактов, вызванных наличием сильнопоглощающих включений в объекте}
\label{im:high_absorb_artifacts}
\end{figure}

Далее структура главы будет следующая: сначала будет приведено описание модели и метода восстановления на основе примера малой размерности.
Затем - приведен способ продолжить полученные результаты для входных данных большей резмерности.
После этого приведено описание метода восстановления на основе мягких ограничений.
Наконец, будут обсуждены полученные результаты и сделаны выводы.

Основной вклад данной главы состоит в следующем: предлагается модель формирования артефактов, вызванных наличиием сильнопоглощающих включений, предлагается метод восстановления на основе данной модели, исследуются результаты работы данного метода на различных входных данных, а также производится сравнение результатов восстановления методов, основанных на квадратичном программировании и на использовании ``мягких'' аддитивных квадратичных штрафов. 
Все предложенные алгоритмы в главе сопровождаются вычислительным экспериментом, результаты которых анализируются в соответствующем разделе.

\section{Модель возникновения артефактов}
\label{sect_2_0}

Предлагаемая модель основывается на предположении о некорректной интерпретации измеренных данных, и в результате неправильно построенной задаче оптимизации для нахождения восстеновленного изображения.
Ренгеновское излучение, проходя через металлическое включение, ослабляется сильнее чем в остальных областях исследуемого образца.
В результате в пиксели детектора, соответствующие высокопоглощающим областям под данным углом проекции, попадает излучение интенсивностью, сравнимой с уровенем шума.
В этом случае измерение будет излишне зашумлено, то есть соотношение сигнал-шум неприемлемо для восстановления, либо после прохождения АЦП в измерениях с этих лучей будет записано значение 0.
Однако все что можно сказать про эти измерения, это что реальное значение в них лежит где-то в интервале $[0, \delta_{min})$, где $\delta_{min}$ --- минимальный порог срабатывания детектора, или уровень шума.
Поэтому и восстановление измерений для этих лучей неоходимо производить отдельно, учитывая механизм их возникновения.

Предлагаемая модель может быть выражена в оптимизационной задаче алгебраического метода в виде ограничений-неравенств.
После обычной для томографии процедуры логарифмирования условие для пикселей $j$ в которых интенсивность пришедшего излучения меньше порога ($I_j < \delta_{min}$) можно записать условие $P_j > \ln\frac{I_0}{\delta_{min}} = \delta$.
Учитывая, что в терминах алгебраического метода $P_j = \sum_i f_i w_{ij}$, оптимизационная задача с учетом предложенной модели будет выглядеть следующим образом:

\begin{equation}
  \label{eq:quadprog_ineq}
  \begin{cases}
  \Norm{P^{\textup{изм.}} - W(f)} \rightarrow \min\limits_f & w.r.t \\
  \sum_i f_{i} w_{ij} > \delta, & \mbox{если } P^{\textup{изм.}}_j = \delta \\
  f_{i} \geq 0
  \end{cases}
\end{equation}

В условия-неравенства оптимизационной задачи (\ref{eq:quadprog_ineq}) так же введены условия-ограничения на неотрицательность значений логарифма линейной функции плотности поглощения рентгеновского излучения $f_i$.
Так как функционал ошибки квадратичный, а ограничения - линейные, для решения этой минимизационной задачи эффективным будет применить метод квадратичного программирования.
При этом в формулировке оптимизационной задачи присутствует полная матрица преобразования Хафа $w_{ij}$.
Как и в случае с алгебраическим методом, решение задачи возможно при использовании итеративной градиентной минимизации, ввиду ее огромной размерности.
Действительно, количество элементов матрицы приблизительно составляет $\sqrt{2} * n * n_\varphi \times n * n$ для изображения размером $n \times n$ и $n_\varphi$ проекционных углов.
При этом ненулевые значения для каждого столбца находятся только в $\approx n$ ячейках, делая возможным использование инструментария для работы с разреженными матрициы.
Несмотря на это, при $n = 256, n_\varphi = 180$ и использовании чисел с плавающей точкой двойной точности (тип данных float64) и способа хранения разреженных матриц ``compressed sparse row'' такая матрица в оперативной памяти вычислителя будет занимать порядка 170Мб.
При этом для традиционных методов решения задачи QP требуется рассчет обратного гессиана целевой функции, то есть матрицы $W W^{\mathrm{T}}$, которая в разреженном виде занимает 11Гб в оперативной памяти и ее невозможно обрабатывать стандартными реализациями ПО для режения задач выпуклого и квадратичного программирования.
Поэтому необходима разработка специальной процедуры, не требующей работы в явном виде с матрицами таких больших размерностей, а лишь с результатами ее умножения на вектор, которое можеь быть вычислено с помощью алгоритмов обработки изображений.

Дальнейшая структура главы следующая: сначала на изображениях малого разрмера будет показана применимость подхода, основанного на предложенной модели возникновения артефактов; после этого будут предложены два подхода к переносу результатов на изображения большего размера, и будет произведено сравнение этих подходов на модельном примере.

\section{Задача квадратичного программирования малой размерности}
\label{sect_2_1}

Для оценки применимости подхода, использующего условную оптимизацию для подавления металлических артефактов, рассматривается модельное распределение линейного коэффициента поглощения размера 10х10 пикселей, содержащее два объекта существенно разной поглощающей способности (рис. \ref{fig:qp_phantom_10by10} а).
Первый объект --- высокопоглощающая (металлическая) ``скобка'' слева фантома, второй --- ``крест'' из более прозрачного материала.
Ожидается что наличие металлического закрывающего объекта затруднит восстановление внутреннего мелкого объекта.
Синограмма данного фантома представлена на рис. \ref{fig:qp_phantom_10by10} б).

% \begin{figure}
%     \centering
%     \begin{tabular}{@{}c@{}c}
%     \includegraphics[width=0.4\textwidth]{../Presentation/images/qp_phantom} 
%     &
%     \includegraphics[width=0.4\textwidth]{../Presentation/images/qp_sino} 
%     \\
%     а) & б)
%     \end{tabular}
%     \caption{а) Модельный фантом размера 10х10 пикселей. б) синограмма}
%     \label{fig:qp_phantom_10by10}
% \end{figure}


\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{part2_img/qp_input_10x10} \\
    а) \hspace{0.5\textwidth} б)
    \caption{а) Модельный фантом размера 10х10 пикселей. б) синограмма --- набор проекций данного фантома для 35 проекционных углов}
    \label{fig:qp_phantom_10by10}
\end{figure}

Порог $\delta$ для экспериментов подбирался таким образом, чтобы обрезать максимумы синограммы.
Значение порога было 800, размер пикселя был 1х1.
Значение сильнопоглощающего включение было 250, слабопоглощающего объекта - 160.
При расчете синограммы использовалось 35 проецкионых углов, равномерно распределенных в интервале от 0 до 180 градусов.

Для вычисления синограммы используется стандартная процедура прямой томографической проекции.
Однако для формирования входных данных для минимизации в задаче квадратичного программирования необходимо вычислить матрицу проекции $W$ поэлементно.

\section{Вычисление значений элементов матрицы проекции}

Действие оператора томографической поекции $W$ на дискретное изображение распределение линейного коэффициента поглощения $f$ легко вычисляется с помощью алгоритмов обработки изображений.
В этом параграфе  предстоит совершить ``обратное'' --- имея возможность делать прямую проекцию вычислить значения элементов матрицы $w_{ij}$
В данном разделе будет построен алгоритм вычисления элементов матрицы, используя декомпозицию оператора $W$ по отдельным лучам проекции а так же линейность самого преобразования томографической проекции.

Действие оператора проекции на изображение обозначается как $\mathbf{p} = W\mathbf{f}$.
Введем калибровочные изображения $\mathbf{f}^{(k)} = \delta_{ik}$, имеющие только один ненулевой пиксель.
За $\delta_{ik}$ обозначен символ Кронекера, т.е. тензор, значения которого удовлетворяют $\delta_{ik} = 1 \text{, если} i = j \text{, иначе } 0$.
Любое изображение на входе оператора проекции можно представить в виде линейной комбинации калиборочных: $\mathbf{f} = \sum_k f_k \mathbf{f}^{(k)}$.
Значит для вычисления элементов линейного оператора $W$ можно затабулировать результаты его применения ко всем калибровочным изображениям:

\begin{equation}
  \label{eq:w_on_calib_img}
  p_j = \left(W \mathbf{f}^{(k)} \right)_j = \sum_i w_{ij} \delta_{ik} = w_{kj}
\end{equation}

В результате алгоритм вычисления значений матрицы $W$ представлен в алг. \ref{alg:hough_matrix}:

\begin{algorithm}[H]
 \KwData{линейный размер входного изображения $n$, количество углов проекции $n_\varphi$}
 \KwResult{значения элементов матрицы $w_{ij}$}
 инициализация нулями матрицы (возможно, разреженной) $W \in \textbf{Mat}\left(nn, nn_\varphi)\right)$\;
 \For{каждого пикселя $k = 0 \dots nn$}{
  вычислить значение проекции калибровочного изображения $\mathbf{p}^{(k)} = W \mathbf{f}^{(k)}$\;
  обновить значение жлементов $w_{kj}$ используя формулу (\ref{eq:w_on_calib_img})\;
 }
 \caption{Алогритм вычисления элементов матрицы $w_{ij}$}
 \label{alg:hough_matrix}
\end{algorithm}

\todo{Подумать над тем, чтобы убрать эти иллюстрации в приложение} \\
Ниже (рис. \ref{fig:w_matrices}) приведены примеры вычислнных матриц для различных разрешений изображения и количества проекционных углов.

\begin{figure}
\centering
\begin{tabular}{c c c}
\includegraphics[width=0.35\textwidth]{../../Presentation/images/w_matrices/W_10_10_plot.png} &
\includegraphics[width=0.25\textwidth]{../../Presentation/images/w_matrices/W_10_35_plot.png} &
\includegraphics[width=0.25\textwidth]{../../Presentation/images/w_matrices/W_16_45_plot.png} \\
\small{$N = 10$, $N_\varphi = 10$} &
\small{$N = 10$, $N_\varphi = 35$} & 
\small{$N = 16$, $N_\varphi = 45$}
\end{tabular}
\caption{Примеры вычисленных матриц проекции W}
\label{fig:w_matrices}
\end{figure}

\section{Метод восстановления}

Формулировка задачи оптимизации, решение которой приводит к восстановленному изображению, приведена в (\ref{eq:quadprog_ineq}).
Это задача квадратичного программирования, хорошо известная и имеющая много готовых реализаций решающего ПО в популярных математических пакетах.
Для проверки подхода были использованы реализации пакета quadprog на языке Matlab \cite{coleman1996reflective} и пакета cvxopt для языка Python \cite{andersen2013cvxopt}.

В общем случае задача квадратичного программирования формулируется как 

\begin{equation}
  \label{eq:quadprog_general}
  \begin{cases}
  \frac 1 2 x^\mathrm{T}Px + q^\mathrm{T}x \rightarrow \min\limits_x & w.r.t \\
  Gx \preceq h \\
  Ax = b\,
  \end{cases}
\end{equation}

где $P$ --- симметричная положительно определнная матрица, а $Gx \preceq h$ означает поэлементное выполнение неравенства.
Одним из эффективных подходов к решению оптимизации такого вида являются методы внутренней точки.
На протяжении всей оптимизационной процедуры решение находится внутри области, удовлетворящей ограничениям.
Постепенно с приближением к оптимуму, решению позвояют приближаться ближе и ближе к границе, и, в конце концов, удовлетворяет необходимой точности решения задачи.
Это достигается за счет введения так называемых барьерных функций для ограничений-неравенств, вклад котрых ослабляется с ходом оптимизации.
А именно, для каждого неравенства $g_i^\mathrm{T}x \leq 0$ в целевую функцию добавляется аддитивный регуляризатор вида $\phi_i(x) = -\frac 1 t \log{\left(- g_i^\mathrm{T}x \right)}$.
Эти функции являются аппроксимациями индикаторной функции ограничений $I_i(x) = 0 \text{, если } g_i^\mathrm{T}x < 0 \text{, иначе} +\inf$.
Внутри области, удовлетворяющей ограничениям, функции являются гладкими.
Легко получить выражение для первой и второй производной барьерных функций:

\begin{equation} 
\label{eq:barrier_grads}
\begin{split}
  \nabla \phi_i(x) &= \frac 1 t \frac {g_i}{-g_i^\mathrm{T}x} \\
  \nabla^2 \phi_i(x) &= \frac 1 t \frac {g_i g_i^\mathrm{T}} {\left( g_i^\mathrm{T}x \right)^2}
\end{split}
\end{equation}

Задача (\ref{eq:quadprog_general}) принимает вид

\begin{equation}
  \label{eq:quadprog_barrier}
  \begin{cases}
  \frac 1 2 x^\mathrm{T}Px + q^\mathrm{T}x + \frac 1 t \phi(x) \rightarrow \min\limits_x & w.r.t \\
  Ax = b\,
  \end{cases}
\end{equation}

где $\phi(x) = \sum_i \phi_i (x) = \sum_i {-\log{\left(- g_i^\mathrm{T}x \right)}}$ --- полная функция со всеми барьерными штрафами. 
Такая задача оптимизации решается методом Ньютона, а именно с помощью итеративной минимизации вида
%\begin{equation} \notag
\begin{gather}
\left(
  \begin{matrix}
  P + \frac 1 t \nabla^2 \phi_i(x) & A ^\mathrm{T} \\
  A & 0
  \end{matrix}
  \right)
  \left(
  \begin{matrix}
  \Delta x \\ \nu
  \end{matrix}
  \right)
  =
  \left(
  \begin{matrix}
  -x^\mathrm{T}P - q^\mathrm{T} - \frac 1 t \nabla \phi(x) \\ 0
  \end{matrix}
  \right),
\end{gather}
где за $\Delta x$ обозначен очередной инкремент итерации.
Далее метод барьерных функций представляет собой последовательное решение ``центрирующих'' задач вида (\ref{eq:quadprog_barrier}) для растущей последовательности параметров $t, \mu t, \mu^2 t \dots$

Метод барьерных функций представляет собой общий инструментарий для рещения задач выпуклого программирования. 
В контексте сформулированной в (\ref{eq:quadprog_ineq}) оптимизационной задачи получается ... \todo{вывести значения P, A G для томографической задачи}


\section{Результаты восстановления}
 \label{sect_2_resutls_qp_10x10}

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{part2_img/qp_foursome_10x10}
  \caption{Восстановление различными методами: a) SIRT, б) FBP, в) QP(с неравенствами), г) QP(без неравенств)}
  \label{im:quadprog}
\end{figure}

Для симуляции использовался фантом, изображенный на рисунке \ref{fig:qp_phantom_10by10}a).
На рисунке \ref{im:quadprog}a,б) представлено восстановление полученной синограммы методами SIRT и свертки и обратной проекции.
Целью данного подраздела является улучшение данного восстановения методом квадратичного программирования.
Результаты восстановления с помощью решения задачи (\ref{eq:quadprog_ineq}) представлены на рисунке \ref{im:quadprog}в,г.
В одном случае использовалась информация, содержащаяся в неравенствах, в другом - все уравнения интерпретировались как равенства.
Интересным результатом является несовпадение результатов восстановлений а) и г).
Это можно объяснить различным количеством произведенных итераций, а так же незначительным раличием в форме итерации.
Для восстановления использовался метод \cite{quadprog_algo}.
Как видно из рисунка, квадратичное программирование с условиями неравенствами обеспечивает лучшее восстановление границ и интенсивностей исходного фантома. 
Значения интенсивностей на разных частях восстановленых фантомов приведены в таблице \ref{tb:quadprog_res}:

\begin{table}[h]
\label{tb:quadprog_res}
\centering
\begin{tabular}{ r| c| c| c| c| c|}
       & \ref{fig:qp_phantom_10by10}a & \ref{im:quadprog}a & \ref{im:quadprog}b & \ref{im:quadprog}c & \ref{im:quadprog}d \\ \hline
скобка & $250$                        & $226.07 \pm 27.64$ & $158.85 \pm 29.83$ & $216.79 \pm 34.79$ & $221.44 \pm 54.49$ \\ \hline
крест  & $160$                        & $124.42 \pm 16.95$ & $80.49 \pm 8.11$   & $148.44 \pm 8.50 $ & $148.76 \pm 62.65$ \\ \hline
\end{tabular}

\caption{Средние значения и стандартное отклонение интенсивностей в разных областях исследуемого фантома}
\end{table}

%FBP :  bracket: 158.85 +- 29.83 cross: 80.49 +- 8.11
%SIRT :  bracket: 226.07 +- 27.64 cross: 124.42 +- 16.95
%QP (с неравенствами) :  bracket: 216.79 +- 34.79 cross: 148.44 +- 8.50
%QP (без неравенств) :  bracket: 221.44 +- 54.49 cross: 148.76 +- 62.65


Так же можно заметить, что использование квадратичного программирование с ограничениями типа неравенство обеспечивет более близкие значения интенсивностей с меньшим значением отклонения.
На рисунках видно, что только метод на основе квадратичного программирования позволяет восстановить полость внутри области слабого поглощения.

\section{Продолжение результата на изображения б\'ольших размерностей}
Результаты, полученные в \ref{sect_2_resutls_qp_10x10} показывают, что необходимая для улучшения восстановления информация может быть выражена в виде неравенств, предложенных в модели.
Однако сам метод, использованный в главе, не подходит для практического применения на современных вычислителях.
Ранее отмечалось, что существующие реализации численных решений задач QP во-первых, требуют на вход вычисления матрицы $WW^{\mathrm T}$, а во-вторых явного обращения этой матрицы как гессиана минимизируемог функционала.

Поэтому основная задача далее --- найти способ воспользоваться информацией из неравенств, оставаясь при этом в рамках вычислительно эффективной процедуры восстановления.
Для этого предлагаются два подхода: метод барьерных функций и метод мягких ограничений. 
Оба этих подхода учитывают неравенства в виде аддитивных слогаемых в оптимизируемом функционале.
В методе мягких ограничений используются стандартные квадратичные штрафы, а методе барьерных функций --- логарифмические, определенные только в области, удовлетворяющей соответствующим неравенствам.

Для получения результатов и исследования обозначенных свойств предлагается фантом, указанный на рис. \ref{fig:qp_phantom_64by64}.
В отличие от примера из предыдущей секции, в данном случае используется физическая симуляция металлического (Au) включения в ткань зуба (Ca).
На рис.\ref{fig:qp_phantom_64by64}а) можно видеть очертания трех низкопоглощающих объектов из кальция (зубов), в среднем из которых присутствует золотое включение.
Параметры гамма-коррекции для иллюстрации подобраны таким образом, чтобы слабопоглощающее включение было контрастно видно на фоне яркого сильно поглощающего.
Для вычисления прямой проекции использовалось 90 проекционных углов, а так же пуассоновский шум.
Амплитуда шума совместно с интенсивностью излучения подбирались экспертом таким образом, чтобы сохранялся приемлимый уровень соотношения сигнал-шум.
Значения полных сечений рассеяния излучения на заданной энергии (45 КэВ) для выбранных материалов рассчитывалось с помощью программной библиотеки XRayLib \cite{xraylib}.
\todo{нужно ли упомянуть что ПО для симуляции и составления фантома а так же программная реализация метода мягких ограничений реализована Соколовым В.?}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{part2_img/qp_input_64x64} \\
    а) \hspace{0.5\textwidth} б)
    \caption{а) Модельный фантом размера 64х64 пикселей. б) синограмма --- набор проекций данного фантома для 90 проекционных углов}
    \label{fig:qp_phantom_64by64}
\end{figure}

Размер изображения 64х64 был выбран из соображений удобства разработки, чтобы иметь возможность производить большое количество тестовых прогонов алгоритмов восстановления на обычном ПК.
При этом методы, рассматриваемые в главе, могут быть применены для восстановления изображений и большего размера.


Обозначим за множество пикселей входной синограммы со значениями больше порога $\mathrm J = \{j | P_j \geq \delta \} \subseteq \{1 \dots n\}$, а так же введем диагональную матрицу-индикатор данного множества 
$$
K \in diag\left\{n \times n_\varphi\right\}; K_{jj} = 0 \text{, если\ } j \in \mathrm J \text{, иначе\ } 1
$$.
Каждому из неравенств, обозначающих вышедшие за порог значения интенсивностей в задаче \ref{eq:quadprog_ineq} соответствует барьерная функция вида $\log{\sum_i f_{i} w_{ij} - \delta}$, если $j \in J$. 
А так же каждому пикселю восстанавливаемого изображения $i$ соответствует барьерная функция вида $\log{f_i}$.
Минимизируемый для решения задачи восстановления функционал принимает вид

\begin{equation}
\label{eq:barrier_method_goal}
  Q(f) = \Norm{K(P - Wf)}_2^2 - 
  \frac 1 t \left( 
    \sum_{j \in \mathrm J}{
      \log{\left(\sum_i {f_i w_{ij} - \delta} \right)}
    }
    +
    \sum_{i}{
      \log{f_i}
    }
  \right)
\end{equation}

Для решения оптимизационной задачи $Q(f) \rightarrow \min\limits_f$ применяется метод градиентного спуска.
Значения градиента для каждого из слагаемых в \ref{eq:barrier_method_goal} рассчитываются следующим образом. 
Первая часть является обычной обратной проекцией ($BP(\cdot)$) невязки, с зануленными элементами, отвечающими $j \in \mathrm J$:
$$
\nabla_f \Norm{K(P - Wf)}_2^2 = 2 W ^ {\mathrm T} (K(Wf - P)) = 
  2 BP\left(K(Wf-P)\right).
$$

Для второго слагаемого, $\sum_j {\left(\log{\left(\sum_i {f_i w_{ij} - \delta} \right)}\right)}$, шаг градиентного спуска будет вычисляться как обратная проекция изображения, составленного из значений 
$$
\hat{h}_j = 
  \begin{cases}
    \left(\sum_i {f_i w_{ij}} - \delta \right)^{-1}, & \text{если}\ j \in \mathrm J \\
    0, & \text{иначе}
  \end{cases}.
$$
Напомним, что на протяжении итерационной процедуры выражение в знаменателе положительное, за $j$ обозначен индекс пикселя в пространстве измерений.
Итак,

$$
\nabla_f \sum_j {\left(
  \log{
    \left( \sum_i {f_i w_{ij}} - \delta \right)
  }
\right)} 
= BP(\hat{h}).
$$

Градиентом для третьего слагаемого будет изображение со значениями $\hat{u}_i = \frac 1 f_i$. Таким образом, шаг градиентного спуска для минимизации функционала $Q(f)$ будет иметь вид:

\begin{equation}
  \label{eq:barrier_method_gradstep}
  f^{\text{нов}} = f - \alpha \left(
    BP\left( K(Wf-P) \right) - 
    \frac 1 t BP(\hat{h}) - 
    \frac 1 t BP(\hat{u})
  \right)
\end{equation}

, где за $\alpha$ обозначен параметр скорости градиентного спуска, или релаксационный параметр.
Настройка итерационного алгоритма, подобного (3) – сложная инженерная задача.
Необходима балансировка вкладов каждой из аддитивных составляющих градиента, чтобы они не выводили за пределы целевого множества. 
Упростить эту настройку может использование операций проекции $f$ на целевое множество: после каждого обновления переменной  необходимо спроецировать ее на множества, задаваемые ограничениями $\sum_i {f_i w_{ij}} \geq \delta$ и $f_i \geq 0$.
Т.к. целевое множество и целевая функция – выпуклые, подобная регуляризация, помимо всего, ускоряет сходимость итерационной процедуры.
Чтобы сохранялась вычислительная стабильность итерационного процесса, проекция в реальности производится на множество, находящее во внутренности обозначенного целевого: $\sum_i {f_i w_{ij}} \geq \delta + \varepsilon$ и $f_i \geq \varepsilon$, где $\varepsilon$ --- некоторое маленькое число.
В описанных численных экспериментах использовалось значение $\frac {10^{-4}}{t}$.

Проекции на множества ограничений, описываемые неравенствами, накладываемыми на восстанавливаемое изображение ($f_i \geq \varepsilon$), выполняются простым обрезанием значений: $f[f < 0] := 0$.
Однако чтобы спроецировать текущее решение на множества описываемые неравенствами относительно проекций, необходимо решить задачу, аналогичную задаче томографического восстановления.
Суть состоит в том, чтобы итеративно производить обратную проекцию по нарушающим ограничение измерениям, т.е. по таким лучам $j \in \mathrm J$, для которых выполняется $\sum_i f_i w_{ij} < \delta$.
Обозначим это множество за $\hat{\mathrm J}$.
Алгоритм проекции на множество ограничений в пространстве измерений представлен в алг. \ref{alg:hough_barrier_projection}.

\begin{algorithm}[H]
 \KwData{текущее значение $f$, количество итераций $N$, допуск $\varepsilon$, скорость спуска $\alpha$}
 \KwResult{результат проекции $f$ на ограничения}
 P = FP(f)
 вычисление $\hat{\mathrm J} = \{j \in \mathrm J | P_j < \delta \}$
 \For{i в интервале от 1 до $N$}{
  \If{$\hat{\mathrm J}$ --- пустое}
  {\KwRet $f$}
  \Else{
    $P[~\hat{\mathrm J}] := 0$
    $P[\hat{\mathrm J}] -= \delta + \varepsilon$
    $f := f - \alpha BP(P)$
  }
 }
 {\KwRet $f$}

 \caption{Вычисление проекции на ограничения, наложенные на проекции, в задаче \ref{eq:quadprog_ineq}}
 \label{alg:hough_barrier_projection}
\end{algorithm}
\todo{ алгоритм проекции на хафовские ограничения }


\begin{algorithm}[H]
 \KwData{измеренные проекции $P$, значение порога $\delta$, количество внешних итераций $n_biter$, начальное значение параметра $t_0$}
 \KwResult{восстановленное изображение $f$}
 

 \todo{ алгоритм метод барьерных функций}

 \caption{Метод барьерных функций для задачи восстановления объектов с наличием сильнопоглощающих включений}
 \label{alg:barrier_method}
\end{algorithm}


\section{Мягкие ограничения на неравенства} \label{sect_2_2}

\begin{comment}

In this paper, we improve the results achieved in \cite{chukalinaway}. First, we provide a robust to noise and admissible to efficient optimization methods way to express the inequalities introduced in \cite{chukalinaway}. Second, we evaluate the method's performance on a simulated phantom data. The phantom data was simulated to remind a teeth with a metal object. And finally we evaluate the gain we get using the information in the inequalities against not using it at all.

The sections are organized as follows. Section \ref{s-approach} outlines the detail our approach to solve the problem. In Section \ref{s-phantom} the simulated phantom is presented. The obtained results are discussed in Section \ref{s-results}. Section \ref{s-conclusion} then concludes the whole paper.

% \section{Описание подхода}
\label{s-approach}
Let us denote the distribution of the attenuation coefficient in the reconstructed volume with $x \in \mathbb{R}^m$. The $p \in \mathbb{R}^n$ denotes the projection data detected during a scan. According to Beer-Lambert law the energy, detected at the detector cell, corresponding to $i$-th ray is expressed by the formula $p_i = I_0 * \exp(-a_i^T x)$, where $I_0$ is the source intensity, and $a_i$ is the row of the projection matrix $A$ corresponding to the $i$-th ray. A standard approach to find $x$ from the projection data is to take a logarithm and solve the linear system of equations: $Ax = r$, where
$r_i = \log(I_0) - \log(p_i)$. A standard way to get robust to noise reconstruction here is to use linear least squares:
\begin{equation} \label{eq:lls}
  \Norm{Ax - r}^2 \to \min\limits_{x}.
\end{equation}

Metal streak artifacts are caused mainly by photon starvation and noise. Mathematically it corresponds to the rays where $p_i$ is small or even zero. In latter case the logarithm is not defined and the simples way is just to ignore those rays solving instead of \eqref{eq:lls}:
\begin{equation}
  \label{eq:mask-lls}
  \Norm{P(Ax - r)}^2 \to \min\limits_{x},
\end{equation}
where matrix $P$ takes only those coordinates of a vector, at which $p_i \neq 0$. More precisely,
$$
P_{i,j} = \begin{cases}
  1, \quad\text{if $i = j$ and $p_i > 0$} \\
  0, \quad\text{otherwise}
  \end{cases}.
$$

It was suggested in \cite{chukalinaway} that even such problematic rays provide us with some information, namely that the weighted sum along such a ray has lower bound $a_i^T x > B$, for some suitable value of $B$ (for example, $B = \log I_0$), and we can use this information in a form of linear inequality constraints, solving the linear system with linear least squares approach:
\begin{equation}
  ||P(Ax - r)||^2 \to \min\limits_x, \quad\textrm{s.t. }  QAx \ge B,
\end{equation}
where $Q$ takes only those coordinates of a vector at which $p_i = 0$, opposite to the matrix $P$. Basically, $Q = E - P$, where $E$ is identity matrix.

This constraints being mathematically correct, are tight and are not robust against the noise in the projection data. Instead of tight constraints we propuse to use a soft version provided with a quadratic penalty method \cite{nocedal2006numerical} instead:
\begin{equation}
  \label{eq:soft-ineq}
  ||P(Ax - r)||^2 + \alpha ||[QAx - B]^-||^2 \to \min\limits_x,
\end{equation}
where $[y]^- = \min\{0, y\}$.

This functional provides a soft way to enforce the inequalities on the variables, but also allows to handle noise effects more smoothly. We can regulate the effect of that smoothing by manipulating $\alpha$: the greater $\alpha$ is tighter the effect of inequalities is.

The objective function \eqref{eq:soft-ineq} is convex and differentiable. We can effectively minimize it with Conjugate Gratient method (we used the implementation of this method, provided by the Python package \cite{scipy}). To speed-up computation of forward and backward tomographic projection operators we used ASTRA Toolbox \cite{palenstijn2011performance, van2015astra} which performs efficient evaluation of such operators on GPU.
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.45]{part2_img/phantom-and-projection}
  \caption{The phantom (left) and its projection at $I_0 = 10^3$ photons (right).}
  \label{phantom-and-projection}
\end{figure}

\section{Описание образца}
\label{s-phantom}
To simulate the sinogram in $55$keV monochromatic mode we used a phantom imitating three teeth. Middle tooth contains titanium include imitating an implant (fig. \ref{phantom-and-projection}, left image). Pixel size is $0.005$cm. 2D field view size is $256 \times 256$ pixels. We used the XRayLib library \cite{brunetti2004library, schoonjans2011xraylib} to calculate the X-ray attenuation in each pixel for chosen energy. The sinogram (fig. \ref{phantom-and-projection}, right image) was calculated in a parallel scheme. We used $512$ rotation angles uniformly distributed in the interval $[0, \pi)$. The number of the detector cells is $362$, so that the diagonal of the phantom is projected on the detector without loosing any information. Such geometry choice allowed us to ignore the uniqueness of the solution issues which are related to the null-space of the projection operator and are ususally dealt with some sort of regularization techniques.

\section{Результаты}
\label{s-results}
To study the proposed approach we generated projections for different source intensities and draw several samples of Poisson noise at each source intensity.

For each projection we reconstructed the volume using Missing Data Least Squares \eqref{eq:mask-lls} and proposed Soft Inequalities Least Squares \eqref{eq:soft-ineq} approaches. The value of $\alpha$ was chosen to be equal to $50$.. The reconstructed volume was then compared to the original phantom and Mean Square Error was compute for such a pair.

In the figure \ref{sample} we can see an example of such reconstructions. In absence of the information encoded in the inequalities the metal artifacts are presented and there is a strong shadow in the cental tooth, while in the left image, reconstructed with Soft Inequalities approach those artifacts are significantly reduced.
\begin{figure}
  \centering
  \includegraphics[scale=0.5]{part2_img/sample}
  \caption{Example of reconstruction with Soft Inequalities method (left)
    and Missing Data method (right).}
  \label{sample}
\end{figure}
In the figure \ref{error-plot} we can see the plot of MSE averaged over all the samples of noise for each noise level. The inequalities provide an improvement over ignoring such data at all noise levels.
\begin{figure}
  \centering
  \includegraphics[scale=0.5]{part2_img/error-plot}
  \caption{The MSE value with respect to noise level.}
  \label{error-plot}
\end{figure}

\section{Выводы}
\label{s-conclusion}

Experiments shows that the information encoded in the inequalites, introduced in \cite{chukalinaway} carries a significant information which can be used to reduce metal-like artifacts in the reconstructions. We proposed a robust way to use this information in form of panaltized objective function. The proposed functional is suitable to be minimized with an efficient numerical algorithms enabling the approach to work on mid- and large-sized data. Proved to work, the method next should be deeper with respect to sensitivity to $\alpha$ and compared against the other approaches mentioned in the introduction. It is also seems possible to leave the penalty encoding the inequality constraints, replacing the least squares functional with more statistically suitable (for example, Poisson log-likelihood, used in MLEM) data fit functional.

\end{comment}

\subsection{параметры моделирования и восстановления} \label{sect_2_3}
Параметры моделирования:
\begin{itemize}
  \item размером фантома (size, 65, 256),
  \item количеством углов проекции (n\_angles, 90, 512), 
  \item интенсивность пучка (i0, 1000)
  \item энергия пучка (45 кэв)
  \item форма фантома (три зуба и имплант-бумеранг)
  \item материалы фантома и импланта (Ca, Au)
  \item наличие импланта (в наличии)
  \item размер пикселя (0.05)
  \item наличием шума при прокеции, распределением шума (есть пуассоновский шум)
\end{itemize}

Параметры восстановления:
\begin{itemize}
  \item итераций 200 (где-то 300)
  \item $\alpha$ 30 и 300
\end{itemize}