\section*{Общая характеристика работы}

\newcommand{\actuality}{\textbf{\actualityTXT}}
\newcommand{\progress}{\textbf{\progressTXT}}
\newcommand{\actualityandprogress}{\textbf{\actualityandprogressTXT}}
\newcommand{\aim}{{\textbf\aimTXT}}
\newcommand{\tasks}{\textbf{\tasksTXT}}
\newcommand{\novelty}{\textbf{\noveltyTXT}}
\newcommand{\influence}{\textbf{\influenceTXT}}
\newcommand{\methods}{\textbf{\methodsTXT}}
\newcommand{\defpositions}{\textbf{\defpositionsTXT}}
\newcommand{\reliability}{\textbf{\reliabilityTXT}}
\newcommand{\probation}{\textbf{\probationTXT}}
\newcommand{\contribution}{\textbf{\contributionTXT}}
\newcommand{\publications}{\textbf{\publicationsTXT}}

%\fontsize{12pt}{12pt}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов ...

%\underline{\textbf{Объем и структура работы.}} Диссертация состоит из~введения, четырех глав, заключения и~приложения. Полный объем диссертации \textbf{ХХХ}~страниц текста с~\textbf{ХХ}~рисунками и~5~таблицами. Список литературы содержит \textbf{ХХX}~наименование.


\textbf{Объем и структура работы.} Диссертация состоит из~введения, четырёх глав, заключения и~двух приложений.
Полный объем диссертации \textbf{56}~страниц текста с~\textbf{10}~рисунками и~2~таблицами. Список литературы содержит \textbf{45}~наименований.

%\newpage
\section*{Содержание работы}
Во \underline{\textbf{введении}} приводится общая характеристика работы, 
обоснована актуальность, цель диссертации, научная новизна, показана теоретическая и практическая значимость исследований, проведённых в рамках данной диссертационной работы, представлены методы исследования, указана степень достоверности и апробация результатов.

В \underline{\textbf{первой главе}} формулируется математическая постановка задачи, приводится обзор актуальных научных подходов к ее решению.

Формулируется модель формирования измерений с параллельным пучком при зондировании монохроматическим излучением. 
Задача восстановления томографических измерений ставится как обращение преобразования Радона 
\begin{equation}\notag
  p(\varphi, \xi) = \ln \left (\frac{I_0}{I(\varphi, \xi)} \right) = 
 \iint \! \mathrm d x \mathrm d y f(x,y)\delta(x\cos\varphi + y\sin\varphi - \xi).
\end{equation}
Задача состоит в восстановлении функции ослабления рентгеновского излучения $f(x,y)$ по набору логарифмированных нормированных проекций под разными углами $p(\varphi, \xi)$.

Для решения этой задачи существует две основных группы методов: интегральные и алгебраические.
Представителем первой группы методов является алгоритм свертки и обратной проекции, или FBP. 
Этот алгоритм основан на обращении фурье-образов измеренных проекций целевой функции.
Будучи основанным на дискретном преобразовании фурье, алгоритм реконструкции имеет низкую вычислительную сложность $O(n^2 \log n)$, однако зачастую в восстановлении этим методом присутствуют искажения и ошибки, называемые артефактами.
Обычно их подавляют с помощью фильтрации на этапе пост-обработки.

Другая группа методов --- алгебраические, использует численные методы решения СЛАУ в дискретном приближении оператора преобразования Радона.
Это приближение называется преобразованием Хафа, и может быть выражено в виде матрицы весов $W \in Mat\left(n^2 \times n ~ n_\varphi\right)$.
Эта матрица линейного пробразования, ставящего в соответствие вектору-изображению внутренней характеристики объекта вектор-изображение логарифма его томографической проекции.
Она имеет большие размеры и является сильно разреженной.
Полученную систему $p = Wf$ решают итерационными методами.
Например, классический алгоритм ART использует метод Карчмарша, метод SIRT --- градиентный спуск, а метод SART --- частичный градиентный спуск по тем координатам градиента, которые соответствуют лучам, направленным под одним углом.
Алгебраические методы являются более вычислительно тяжелыми:
асимптотическое время работы одной итерации растет кубическим образом с ростом разрешение восстанавливаемого изображения, а количество итераций, необходимых для достижения заданного значения функции потерь может доходить до тысяч.
В то же время они позволяют добиться лучшего качества восстановления, чем интегральные: во-первых, они не страдают от характерных сферических фурье-артефактов, во-вторых, позволяют вносить корректировки в процесс восстановления на каждой итерации.
Алгебраические методы позволяют учесть специфику задачи и причину возникновения конкретных артефактов, учитывая это во время восстановления, а не на этапе постобработки.

К таким артефактам можно отнести артефакты вызванные наличием сильнопоглощающих включений.
Столкнуться с такими артефактами можно, например, при медицинском сканировании пациента с металлическими коронками в зубах или костными протезами.
Причиной таких артефактов является недостаточное количество фотонов, проходящих через такие включения.
Для борьбы с ними используют как аппаратные так и праграммные методы.
Примерами аппаратных могут быть адаптивное расширение детектирующей ячейки в местах дефицита фотонов, зондирование несколькими энергиями, автоматическая модуляция тока в электронно-лучевой трубке.
Чтобы бороться с данным эффектом программно, испоьлзуют адаптивные фльтры, интерполяцию и статистические методы, например метод максимального правдоподобия, чтобы исправить синограмму в местах некорректно интерпретируемых данных.

Одной из причин возникновения артефактов, в том числе и вызыванных наличием сильнопоглощающих включений, является отсутствие учета полихроматичности спектра источника в модели формирования томографических измерений.
Обычно с этим связывают появление эффекта огрубления луча, или beam hardening.
Для борьбы с этим типом артефактов применяют как физические методы борьбы, так и программные.
Изменения в экспериметнальной схеме состоят в том, чтобы приблизить экспериментальную схему к модельной (применение монохроматоров), либо собрать больше информации при измерении (зондирование на разных энергиях.
Программная борьба с этим эффектом --- область активных исследований.
Применяются такие методы как предобработка синограммы, переход к решению задачи восстановления концентраций, поиск решений на низкоразмерных многообразиях, оценивание коэффициента ослабления для нескольких дискретных энергий (pSART).

Во \underline{\textbf{второй главе}} предложен и обсуждается асимптотически быстрый алгоритм SART, основанный на реализации быстрого преобразования Хафа (БПХ).
Алгоритм решает задачу восстановления для случая зондирования монохроматическим параллельным излучением.
Представлено доказательство асимптотической оценки сложности алгоритма.
Численная реализация алгоритма проиллюстрирована результатами реконструкции модельного изображения размером 256 $\times$ 256 по полному набору 1021 углов БПХ и по разреженным синограммам, имеющим до 11 раз меньшее число проекционных углов.

Обычно итерация алгебраического метода выглядит как шаг в направлении антиградиента минимизируемого функционала ошибки:
\begin{equation}\notag
  \Delta \textbf f = \sum_\varphi {{W^\varphi}^{\mathrm T}(\textbf p - W\textbf f) } = W^{\mathrm T}(\textbf p - W \textbf f).
\end{equation}
где $W$ это оператор преобразования Хафа или томографической проекции.
  
Для асимптотического ускорения итерации алгебраического метода предлагается использовать приближенное вычисление преобразования Радона для конечного набора углов (преобразование Хафа), основанное на диадических паттернах --- быстрое преобразование Хафа.
Общая схема алгоритма состоит в следующем: сначала данные эксперимента трансформируются, чтобы реальные углы и смещения измерительной схемы соответствовали правильным координатам изображения, полученного после БПХ.
\todo{вставить формулы и картинки с четвертями БПХ}
После этого происходит итеративная процедура, вычисляющая прямую проекцию от текущей гипотезы о восстанавливаемом объекте, вычислении невязки, вычисления градиента невязки и обновления гипотезы.
Замена поворота в модели прямой проекции производится очевидным образом.
При вычислении невязки нужно учитывать отсутствующие измерения в реальных экспериментальных данных: например, если число проекционных углов составляет $n_\varphi$, то в хафовских координатах такая картина будет иметь нули по $4 * n - 3 - n_\varphi$ угловым отсчетам.

Эффективная реализация обратной проекции (вычисления градиента невязки) с помощью БПХ требует детального описания.
БПХ-изображение можно разделить на 4 части по направлениям линий проекции: вертикальные-левые, вертикальные-правые, горизонтальные-левые и горизонтальные-правые.
Соответственно, матрица проекции $W$ тоже разделяется на 4 независимые части по строкам.
Для каждой четверти преобразования Хафа выполняются аналогичные действия.

Показано, что можно использовать метод FHT-SIRT для восстановления томографии.
При этом одна итерация зависит только от четверти проекционных углов, поэтому возможно использовать модификацию FHT-SART чтобы сделать итерационный процесс ближе к методу SART, который обладает лучшей сходимостью.
Использование FHT-SIRT позволяет снизить асимптотическую сложность одной итерации метода с $O(n^2 * n_\varphi) \approx O(n^3)$ до $O(n^2 \log n)$.
При восстановлении данных реальных экспериментов количество и значения проекционных углов не соответствуют полностью заполненному FHT-преобразованию. 
Исследовано влияние степени разрежения на качество сходимости \ref{fig:conv_all} a).

\begin{figure}
\centering
\begin{tabular}{@{}c@{}c}
    \includegraphics[width=0.45\textwidth]{Dissertation/images/part1_img/raw}
&
    \includegraphics[width=0.45\textwidth]{Dissertation/images/part1_img/medk}
\\
   \small a) & \small b)
\end{tabular}
  \caption{Зависимость среднеквадратичной ошибки изображения от числа итераций.}
Число рядом с кривой соответствует степени разрежения. а --- Без регуляризации, б --- Медианная регуляризация.
\label{fig:conv_all}
\end{figure}

Кроме того, при переводе синограммы из измеренных координат $\rho, \varphi$ в координаты пространства БПХ, нужно учесть изменение ширины БПХ-луча, то есть отнормировать соответствующую строчку синограммы по ширине и интенсивности.

Для лучшей сходимости метода исследуются возможные регуляризации при применении метода FHT-SART.
Исследуются регуляризация с применением медианного, билатерального фильтров, а так же регуляризация по Тихонову.
Приводятся результаты восстановления с применением указанных видов регуляризации.
В частности, сравнение сырого восстановления с медианной регуляризацией, приведено на рис. \ref{fig:conv_all}.


В \underline{\textbf{третьей главе}} предложена модель формирования измерений при наличии в объекте сильнопоглощающих включений.
При прохождении через такие включения, например, металлический протез в зубе, большая часть зондирующего излучения поглощается.
В результате количество фотонов, доходящих до детектора недостаточно для активации его пикселя.
При измерении с таких пикселей считывается значение 0, хотя, на самом деле, можно лишь сказать, что значение, считанное с этих пикселей находится где-то в интервале $[0, \delta_{min})$, где $\delta_{min}$ --- минимальный порог срабатывания детектора, или уровень шума.
Восстановление без учета ошибок, содержащихся в синограмме, приведет к возникновению артефактов и неточностей восстановления (рис. \ref{im:quadprog}b,c). 

Для того, чтобы избежать появления этих артефактов, задачу восстановления томографии в алгебраическом подходе можно модифицировать, введя ограничения типа неравенства для измерений, значение которых 0 (или $<  \delta_{min}$).
При рассмотрении прологарифмированных значений, условие $I < \delta_{min}$ переходит в условие $f > \ln\frac{I_0}{\delta_{min}} = \delta$.
С учетом перехода к логарифмам измеренной интенсивности, 

\begin{equation} \notag
  \label{eq:quadprog_ineq}
  \begin{cases}
  \Norm{P^{\textup{изм.}} - W(f)} \rightarrow \min\limits_f & w.r.t \\
  \sum_i f_{i} \omega_{ij} = P_j, & \mbox{если } P^{\textup{изм.}}_j < \delta \\
  \sum_i f_{i} \omega_{ij} > \delta, & \mbox{если } P^{\textup{изм.}}_j = \delta
  \end{cases}
\end{equation}

Так как функционал ошибки квадратичный, а ограничения - линейные, для решения этой минимизационной задачи эффективным будет применить метод квадратичного программирования.
При этом в формулировке оптимизационной задаче присутствует полная матрица преобразования Хафа $\omega_{ij}$.
Для разрешения восстановления 256х256 и 180 проекционных углов при использовании типа данных float64 такая матрица будет занимать порядка 32Гб.
Общая формула для расчета размера матрицы это $\sqrt(2) * M * M_\varphi \times M * M$.
При этом ненулевые значения для каждого столбца находятся только в $\approx M$ ячейках, делая возможным использование инструментов разреженных матриц.

Результаты востановления методом квадратичного программирования приложены на рис. \ref{im:quadprog}.
Для упрощения вычислений использовался небольшой фантом размера 10х10 пикселей и 35 проекционных углов.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{Dissertation/images/part2_img/quadprog}
  \caption{Слева сверху a) - фантом использовавшийся для симуляций. Справа сверху b)- результат восстановления FBP. Слева снизу c) - результат восстановления квадратичным программированием без ограничений-неравенств. Справа снизу d) - результат восстановление квадратичным программированием с ограничениями-неравенствами (предложенный метод)}
  \label{im:quadprog}
\end{figure}

Использование жестких ограничений может быть нестабильно отностильно наличия шумов в данных и неточностей их получения.
Для борьбы с этим можно заменить уравнения ограничений задачи оптимизации на аддитивные регуляризирующие штрафы, выражающие эти ограничения.
Этот подход называется методом мягких ограничений.
В контексте решаемой задачи и ее ограничений, предлагается ввести квадратичные штрафы за нарушение в восстановленной функции выхода за границы порога $\delta$.
Если ввести диагональные матрицы-индикаторы нарушения ограничений, $J_{ii} = \left\{1, \mbox{если} \left(\sum f_{i} \omega_{ij} > \delta \right), \mbox{иначе } 0\right\}$, и $K = E - J$, задача минимизации с мягкими ограничениями будет выглядеть как

\begin{equation} \notag
  \label{eq:soft-ineq}
  ||K(Wf - P^{\textup{изм}})||^2 + \alpha ||J(Wf - \Delta)||^2 \to \min\limits_f,
\end{equation}

Производятся исследования метода мягких ограничений на основе данных реальных экспериментальных измерений.
Восстановления симулированных фантомов, а так же образца реального образца, можно наблюдать на рисунках.
В работе производится сравнение восстановления методами мягких ограничений и метода квадратичного программирования.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{Dissertation/images/part2_img/sample}
  \caption{Реконструкции методом мягких ограничений.}
  \label{sample}
\end{figure}

В \underline{\textbf{четвертой главе}} предложен алгебраический метод для восстановления томографических измерений при зондировании полихоматическим илучением.
В большом количестве экспериментальных схем спектр источника является полихроматическим, то есть энергия источника имеет нетривиальный несингулярный спектр.
Это обусловлено сложностью получения монохроматического рентгеновского излучения --- требуется либо излучение, полученное на синхротроне, либо использование монохроматора.
Свойства поглощения материалом излучения меняется в зависимости от частоты зондирующих электромагнитных волн.
В результате, реальная измеренная детектором интенсивность рентгеновского излучения не соответствует модели, используемой в обычных монохроматических алгоритмах восстановления.
Это значит, что заложенные в алгоритме модели прямой и обратной проекции либо не будут неспособны обеспечить сходимость оптимизационной процедуры, либо сойдутся к ложному минимуму, не являющемуся в реальности решением физической задачи.
В обоих случаях восстановление обычными алгоритмами синограммы, снятой при зондировании немонохроматическим излучением, повлечет появление артефактов восстановления.

В данной главе рассматривается метод, позволяющий учесть спектральные особенности взаимодействия материалов объекта с излучением.
При этом предлагается перейти от восстановления коэффициента ослабления излучения к восстановлению пространственного распределения концентраций элементов, спектральные коэффициенты взаимодействия которых с рентгеновским излучением известны: коэффициенты $c_k(x,y)$:

\begin{equation} \notag
  \label{eq:white_fp_final}
  I(c)_j = \int_0^{+\infty} {d\lambda \left\{
    I_0(\lambda) \exp{\left(
      -\sum_{k=1}^K {\rho \kappa_k(\lambda) (W c_k)_j} 
      \right)}
  \right\}}
\end{equation}

,где за $\kappa_k(\lambda)$ обозначен коэффициент поглощения вещества $k$ на длине волны $\lambda$, а $I_0(\lambda)$ --- спектр источника.
Следуя алгебраическому подходу, и выписывая шаг градиентного спуска для квадратичной функции потерь, общий вид итерации восстановления будет иметь вид

\begin{equation} \notag
\label{eq:part3_whitegrad}
  \nabla_k \ Q = 2W^\intercal R_k \text{, где } R_{kj} = \frac {(I(c) - t)_j} {S} \mu_{kj}
\end{equation}
, а формулы для вычисления весов невязок по каждому элементу
\begin{equation} \notag
  \label{eq:weights}
  \mu_{k} = \int_0^{+\infty} {d\lambda \left\{
    -\rho f_k(\lambda) 
    I_0(\lambda)
    \exp{\left(
      -\sum_{s=1}^K {\rho \kappa_s(\lambda) (W c_s)} 
         \right)}
    \right\}}
\end{equation}

В указанной итерационной схеме отсутсвует пространственные различия в формулах обновления концентраций разных элементов. 
Поэтому необходимо вводить дополнительную регуляризацию.
Предлагаемое решение состоит в том, чтобы запретить находиться в одной пространственной ячейке одновременно разным материалам $c_{k_1} \odot c_{k_2} = 0, \mbox{если } k_1 \neq k_2$, что при применении метода мягких ограничений выглядит как аддитивный регуляризующий член 
\begin{equation} \notag
	\sum_{k_1 != k_2} {||c_{k_1} \odot c_{k_2}||^2})
\end{equation}

Здесь за $c_{k_1} \odot c_{k_2}$ обозначено поэлементное умножение массивов.
На рисунке \ref{fig:whiteres} представлены результаты восстановления для фантома с использованием и без использования регуляризации
\begin{figure}
\label{fig:whiteres}
\centering
\begin{tabular}{@{}c@{}c}
  \includegraphics[width=0.45\textwidth]{Dissertation/images/part3_img/no_reg_iteration_25} &
  \includegraphics[width=0.45\textwidth]{Dissertation/images/part3_img/mul_reg_iteration_150}
  \\
  а) &
  б)
\end{tabular}
\caption{Восстановление с помощью МВН. а) без регуляризации. б) мультипликативная регуляризация}
\end{figure}


В \underline{\textbf{заключении}} приведены основные результаты работы, которые заключаются в следующем:
\input{common/concl}

\begin{comment}
%\newpage
При использовании пакета \verb!biblatex! список публикаций автора по теме
диссертации формируется в разделе <<\publications>>\ файла
\verb!../common/characteristic.tex!  при помощи команды \verb!\nocite! 
\end{comment}

\newpage
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
  \renewcommand{\bibname}{\large \authorbibtitle}
  \nocite{*}
  \insertbiblioauthor           % Подключаем Bib-базы
  %\insertbiblioother   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
  \ifnumgreater{\value{usefootcite}}{0}{
%  \nocite{*} % Невидимая цитата всех работ, позволит вывести все работы автора
  \insertbiblioauthorcited      % Вывод процитированных в автореферате работ автора
  }{
  \insertbiblioauthor           % Вывод всех работ автора
%  \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
%  \insertbiblioauthorimportant  % Вывод наиболее значимых работ автора (определяется в файле characteristic во второй section)
  \insertbiblioother            % Вывод списка литературы, на которую ссылались в тексте автореферата
  }
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}

